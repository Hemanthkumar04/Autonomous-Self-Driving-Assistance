import pandas as pd
import numpy as np
import cv2
from PIL import Image
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
!pip install openpyxl
import openpyxl
from google.colab import drive
drive.mount('/content/drive')


car_data = pd.read_excel('/content/drive/My Drive/car/CAR1.xlsx')
car_image_paths = car_data['image_url'].tolist()
car_data.head()
car_data.isnull().sum()
car_data['occupant_changed'].fillna(1,inplace = True)


import os
from concurrent.futures import ThreadPoolExecutor
def load_images(image_paths, target_size=(224, 224), batch_size=100):
    images = []
    c = 0  # Counter for printing progress
    with ThreadPoolExecutor(max_workers=4) as executor:
        for i, path in enumerate(image_paths):
            if c < batch_size:
                executor.submit(process_image, path, target_size, images)
                c += 1
            else:
                c = 0  # Reset counter
                print(f"Processed {i+1} images")
    return np.array(images)

def process_image(path, target_size, images):
    img = cv2.imread(path)
    if img is not None:
        img = cv2.resize(img, target_size)
        images.append(img)

def display_images(images, num_images=10):
    for i in range(min(num_images, len(images))):
        print(f"Displaying image {i+1}:")
        plt.imshow(cv2.cvtColor(images[i], cv2.COLOR_BGR2RGB))
        plt.axis('off')
        plt.show()


car_images = load_images(car_image_paths)
display_images(car_images)


car_images = car_images.astype('float32') / 255.0

print(car_images.shape)
print(car_data.shape)

car_data_filtered = car_data.iloc[:66412]


x_train, x_test, y_train, y_test = train_test_split(car_images, car_data_filtered["occupant_changed"], test_size=0.2,shuffle = True ,random_state=42)

save_dir = '/content/drive/My Drive/car_data/'

if not os.path.exists(save_dir):
    os.makedirs(save_dir)

np.save(os.path.join(save_dir, 'x_train.npy'), x_train)
np.save(os.path.join(save_dir, 'x_test.npy'), x_test)
np.save(os.path.join(save_dir, 'y_train.npy'), y_train)
np.save(os.path.join(save_dir, 'y_test.npy'), y_test)





load_dir  =  '/content/drive/My  Drive/car_data/'

x_train = np.load(os.path.join(load_dir, 'x_train.npy'))
x_test = np.load(os.path.join(load_dir, 'x_test.npy'))
y_train = np.load(os.path.join(load_dir, 'y_train.npy'))
y_test = np.load(os.path.join(load_dir, 'y_test.npy'))

print("Loaded x_train shape:", x_train.shape)
print("Loaded x_test shape:", x_test.shape)
print("Loaded y_train shape:", y_train.shape)
print("Loaded y_test shape:", y_test.shape)


from  sklearn.svm  import  SVC
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score
from sklearn.utils import shuffle



x_train,  y_train  =  shuffle(x_train,  y_train)

from sklearn.model_selection import RandomizedSearchCV
import pickle

classifier  =  SVC()
parameters  =  {'gamma':  [0.01,  0.001],  'C':  [1,  10]}

grid_search  =  GridSearchCV(classifier,  parameters,  cv=3,  n_jobs=-1)
c  =  0;
batch_size  =  1000
num_batches = len(x_train) // batch_size
for i in range(num_batches):
	start_idx = i * batch_size
	end_idx = (i + 1) * batch_size
	x_train_batch = x_train[start_idx:end_idx].reshape(batch_size, -1)
	y_train_batch = y_train[start_idx:end_idx]

	grid_search.fit(x_train_batch,y_train_batch)
	c = c + 1
	print(c)


model_path = '/content/drive/My Drive/car_data/grid_search_model.pkl'
with open(model_path, 'wb') as f:

  pickle.dump(grid_search, f)

best_estimator = grid_search.best_estimator_
x_test_flat  =  x_test.reshape(x_test.shape[0],  -1)

y_pred = best_estimator.predict(x_test_flat)
score = accuracy_score(y_pred, y_test)

print("Accuracy:", score * 100)

model_path = '/content/drive/My Drive/best_estimator.pkl'
with open(model_path, 'wb') as f:
  pickle.dump(best_estimator,  f)
